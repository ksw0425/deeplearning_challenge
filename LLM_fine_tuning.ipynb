{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQj9vG-8Cl-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb401979-fd05-42bf-a3ee-c1f198af0ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bitsandbytes version: 0.47.0\n",
            "transformers version: 4.55.4\n"
          ]
        }
      ],
      "source": [
        "import bitsandbytes as bnb\n",
        "import transformers\n",
        "\n",
        "print(\"bitsandbytes version:\", bnb.__version__)\n",
        "print(\"transformers version:\", transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bft7haCVyEYU"
      },
      "outputs": [],
      "source": [
        "import os, io\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from urllib.request import Request, urlopen\n",
        "from urllib.parse import urlparse\n",
        "from urllib.error import URLError, HTTPError\n",
        "\n",
        "# ===== ì„¤ì • =====\n",
        "inputs_file = \"/content/drive/MyDrive/Colab Notebooks/wook/deeplearningchallenge/deep_chal_multitask_dataset.parquet\"\n",
        "URL_TIMEOUT = 20\n",
        "\n",
        "# ===== ìœ í‹¸ =====\n",
        "def is_url(s: str) -> bool:\n",
        "    try:\n",
        "        return urlparse(str(s)).scheme in (\"http\", \"https\")\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_valid_image_url(u: str, timeout: int = URL_TIMEOUT) -> bool:\n",
        "    \"\"\"URLì´ ì¡´ì¬í•˜ê³ , ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ë””ì½”ë”© ê°€ëŠ¥í•œì§€ ì ê²€\"\"\"\n",
        "    try:\n",
        "        req = Request(u, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        with urlopen(req, timeout=timeout) as r:\n",
        "            raw = r.read()\n",
        "        if len(raw) < 32:\n",
        "            return False\n",
        "        # ì†ìƒ íŒŒì¼/HTML ì‘ë‹µ ê±¸ëŸ¬ë‚´ê¸°\n",
        "        bio = io.BytesIO(raw)\n",
        "        Image.open(bio).verify()   # í¬ë§·/ë¬´ê²°ì„± ì ê²€\n",
        "        # ì¬ì˜¤í”ˆí•´ì„œ ì‹¤ì œ ë””ì½”ë”© ê°€ëŠ¥í•œì§€ë„ í™•ì¸\n",
        "        Image.open(io.BytesIO(raw)).convert(\"RGB\")\n",
        "        return True\n",
        "    except (HTTPError, URLError, TimeoutError, Image.UnidentifiedImageError):\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# ===== ë¡œë“œ =====\n",
        "df = pd.read_parquet(inputs_file)\n",
        "n_total = len(df)\n",
        "\n",
        "# ì»¬ëŸ¼ ì¡´ì¬ ì²´í¬\n",
        "for col in (\"input_type\", \"input\"):\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"'{col}' column is required, but not found in the dataset.\")\n",
        "\n",
        "# URL ì´ë¯¸ì§€ í–‰ë§Œ íƒ€ê¹ƒíŒ…\n",
        "mask_image = df[\"input_type\"].astype(str).str.lower().eq(\"image\")\n",
        "mask_url   = df[\"input\"].astype(str).apply(is_url)\n",
        "target_idx = df[mask_image & mask_url].index\n",
        "\n",
        "# ì ê²€ & ì œê±° ëª©ë¡ ìˆ˜ì§‘\n",
        "bad_idx = []\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **k): return x\n",
        "\n",
        "for i in tqdm(target_idx, total=len(target_idx), desc=\"Checking image URLs\"):\n",
        "    u = str(df.at[i, \"input\"])\n",
        "    if not is_valid_image_url(u):\n",
        "        bad_idx.append(i)\n",
        "\n",
        "# ì œê±° ë° ì €ì¥\n",
        "clean_df = df.drop(index=bad_idx).reset_index(drop=True)\n",
        "\n",
        "base_dir, base_name = os.path.split(inputs_file)\n",
        "stem = os.path.splitext(base_name)[0]\n",
        "out_path = os.path.join(base_dir, f\"{stem}_clean.parquet\")\n",
        "clean_df.to_parquet(out_path, index=False)\n",
        "\n",
        "# ë¦¬í¬íŠ¸\n",
        "print(\"=== URL ì´ë¯¸ì§€ ì •ë¦¬ ê²°ê³¼ ===\")\n",
        "print(f\"ì´ í–‰         : {n_total}\")\n",
        "print(f\"URL ì´ë¯¸ì§€ í–‰ : {len(target_idx)}\")\n",
        "print(f\"ì œê±°ëœ í–‰     : {len(bad_idx)}\")\n",
        "print(f\"ë‚¨ì€ í–‰       : {len(clean_df)}\")\n",
        "print(f\"ì €ì¥ ê²½ë¡œ     : {out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNdsQ9_G87z9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# ì´ë¯¸ ì„¸ì…˜ì— ì¡´ì¬í•œë‹¤ê³  ê°€ì •: df (ì›ë³¸ DataFrame), bad_idx (ì œê±° ëŒ€ìƒ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸)\n",
        "assert 'df' in globals(), \"dfê°€ ì„¸ì…˜ì— ì—†ìŠµë‹ˆë‹¤.\"\n",
        "assert 'bad_idx' in globals(), \"bad_idxê°€ ì„¸ì…˜ì— ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "# 1) ì œê±° ì¸ë±ìŠ¤ 5ê°œ ë¯¸ë¦¬ë³´ê¸°\n",
        "print(\"=== ì œê±° ì¸ë±ìŠ¤ ë¯¸ë¦¬ë³´ê¸°(5) ===\")\n",
        "preview_idx = bad_idx[:5]\n",
        "print(preview_idx)\n",
        "\n",
        "# 2) í•´ë‹¹ ì¸ë±ìŠ¤ì˜ URL 5ê°œ í™•ì¸\n",
        "print(\"\\n=== ì œê±°ëœ í–‰ì˜ URL(5) ===\")\n",
        "preview_urls = df.loc[preview_idx, \"input\"].astype(str).tolist()\n",
        "for i, u in enumerate(preview_urls, 1):\n",
        "    print(f\"{i}. {u}\")\n",
        "\n",
        "# 3) ì „ì²´ ì œê±° ì¸ë±ìŠ¤/URL ì €ì¥ (ì›ë³¸ parquetì™€ ê°™ì€ ìœ„ì¹˜ì—)\n",
        "inputs_file = \"/content/drive/MyDrive/Colab Notebooks/wook/deeplearningchallenge/deep_chal_multitask_dataset.parquet\"\n",
        "base_dir, base_name = os.path.split(inputs_file)\n",
        "stem = os.path.splitext(base_name)[0]\n",
        "\n",
        "idx_json = os.path.join(base_dir, f\"{stem}_removed_indices.json\")\n",
        "with open(idx_json, \"w\") as f:\n",
        "    json.dump(list(map(int, bad_idx)), f)\n",
        "print(f\"\\n[ì €ì¥] ì œê±° ì¸ë±ìŠ¤ JSON: {idx_json}\")\n",
        "\n",
        "idx_csv = os.path.join(base_dir, f\"{stem}_removed_indices.csv\")\n",
        "pd.DataFrame({\n",
        "    \"index\": list(map(int, bad_idx)),\n",
        "    \"input\": df.loc[bad_idx, \"input\"].astype(str).values\n",
        "}).to_csv(idx_csv, index=False)\n",
        "print(f\"[ì €ì¥] ì œê±° ì¸ë±ìŠ¤+URL CSV: {idx_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlJGNdCLHQMW"
      },
      "source": [
        "1. ë°ì´í„° ë¶„í• (trian, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FERVmpLh_cvW"
      },
      "outputs": [],
      "source": [
        "from qlora_vl_qwen_25 import build_train_valid\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning\"\n",
        "\n",
        "# 1) ë¶„í•  (ë¼ë²¨ í¬í•¨ íŒŒì¼ì´ë¯€ë¡œ labels_file=None)\n",
        "train_df, valid_df = build_train_valid(\n",
        "    out_root=OUT_DIR,\n",
        "    inputs_file=\"/content/drive/MyDrive/Colab Notebooks/wook/deeplearningchallenge/deep_chal_multitask_dataset_clean.parquet\",\n",
        "    labels_file=None,\n",
        "    valid_ratio=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMkw5tQ9HUpg"
      },
      "source": [
        "2. LLM fine-tuning ì¤€ë¹„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHYGX6g18KsM"
      },
      "outputs": [],
      "source": [
        "import importlib, qlora_vl_qwen_25 as m\n",
        "import torch\n",
        "\n",
        "m.IMG_BASE = \"/content\"  # ìƒëŒ€ê²½ë¡œ ì“°ë©´ ë§ì¶°ì£¼ì„¸ìš”\n",
        "OUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning\"\n",
        "\n",
        "m.train_model(\n",
        "    base_model=m.DEFAULT_BASE_MODEL,\n",
        "    train_file=f\"{OUT_DIR}/datasets/qlora/train.parquet\",\n",
        "    valid_file=f\"{OUT_DIR}/datasets/qlora/valid.parquet\",\n",
        "    out_root=OUT_DIR,\n",
        "    profile=\"balanced\",\n",
        "    add_task_hint=True,\n",
        "    lora_r=64, lora_alpha=128, lora_dropout=0.05,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQfJ-CicwdJz"
      },
      "outputs": [],
      "source": [
        "from urllib.request import Request, urlopen\n",
        "from urllib.error import HTTPError, URLError\n",
        "\n",
        "URL_TIMEOUT = 10\n",
        "url = \"https://pulpcovers.com/wp-content/uploads/2012/01/36591544-6652526511_fe9af8fcd6_o1.jpg\"\n",
        "\n",
        "try:\n",
        "    req = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    with urlopen(req, timeout=URL_TIMEOUT) as r:\n",
        "        print(\"Response status:\", r.status)\n",
        "        content_length = len(r.read())\n",
        "        print(\"Downloaded bytes:\", content_length)\n",
        "except HTTPError as e:\n",
        "    print(\"HTTPError:\", e.code, e.reason)\n",
        "except URLError as e:\n",
        "    print(\"URLError:\", e.reason)\n",
        "except Exception as e:\n",
        "    print(\"Other Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDIMujKP1CdP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "import os\n",
        "import io\n",
        "from tqdm.auto import tqdm\n",
        "from urllib.parse import urlparse\n",
        "import warnings\n",
        "\n",
        "# ===============================================================\n",
        "# âš ï¸ ì„¤ì •: ìì‹ ì˜ í™˜ê²½ì— ë§ê²Œ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì„¸ìš”.\n",
        "# ===============================================================\n",
        "# ì›ë³¸ ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid.parquet\"\n",
        "\n",
        "# ë‹¤ìš´ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë” ê²½ë¡œ\n",
        "IMAGE_SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/images_v\"\n",
        "# ===============================================================\n",
        "\n",
        "# ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)\n",
        "print(f\"ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ê²½ë¡œ: {IMAGE_SAVE_DIR}\")\n",
        "\n",
        "df = pd.read_parquet(DATASET_PATH)\n",
        "image_rows = df[df['input_type'] == 'image'].copy()\n",
        "print(f\"ì´ {len(image_rows)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\")\n",
        "\n",
        "downloaded_paths = []\n",
        "\n",
        "for index, row in tqdm(image_rows.iterrows(), total=len(image_rows), desc=\"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘\"):\n",
        "    url = row['input']\n",
        "    try:\n",
        "        # URLì—ì„œ íŒŒì¼ ì´ë¦„ ì¶”ì¶œ\n",
        "        parsed_url = urlparse(url)\n",
        "        # ê³ ìœ í•œ íŒŒì¼ëª…ì„ ìœ„í•´ ì¸ë±ìŠ¤ì™€ ì›ë³¸ íŒŒì¼ëª…ì„ ì¡°í•©\n",
        "        filename = f\"{index}_{os.path.basename(parsed_url.path)}\"\n",
        "        save_path = os.path.join(IMAGE_SAVE_DIR, filename)\n",
        "\n",
        "        # ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë‹¤ìš´ë¡œë“œ ê±´ë„ˆë›°ê¸°\n",
        "        if os.path.exists(save_path):\n",
        "            downloaded_paths.append(save_path)\n",
        "            continue\n",
        "\n",
        "        response = requests.get(url, timeout=20, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        response.raise_for_status() # HTTP ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ\n",
        "\n",
        "        # ì´ë¯¸ì§€ê°€ ìœ íš¨í•œì§€ í™•ì¸\n",
        "        img = Image.open(io.BytesIO(response.content))\n",
        "        img.verify() # ì´ë¯¸ì§€ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬\n",
        "\n",
        "        # ìœ íš¨í•˜ë©´ íŒŒì¼ë¡œ ì €ì¥\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        downloaded_paths.append(save_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì¸ë±ìŠ¤: {index}, URL: {url}): {e}\")\n",
        "        downloaded_paths.append(None) # ì‹¤íŒ¨í•œ ê²½ìš° Noneìœ¼ë¡œ í‘œì‹œ\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì˜ 'input' ì—´ì„ ë‹¤ìš´ë¡œë“œëœ ë¡œì»¬ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸\n",
        "image_rows['input'] = downloaded_paths\n",
        "\n",
        "# ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ë°ì´í„°ì™€ ë‹¤ì‹œ í•©ì¹˜ê¸°\n",
        "non_image_rows = df[df['input_type'] != 'image']\n",
        "updated_df = pd.concat([non_image_rows, image_rows]).sort_index()\n",
        "\n",
        "# ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í•œ ë°ì´í„°ëŠ” ì œì™¸\n",
        "updated_df.dropna(subset=['input'], inplace=True)\n",
        "\n",
        "# ìˆ˜ì •ëœ ë°ì´í„°ì…‹ì„ ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
        "UPDATED_DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_local.parquet\"\n",
        "updated_df.to_parquet(UPDATED_DATASET_PATH, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë°ì´í„°ì…‹ ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
        "print(f\"ì—…ë°ì´íŠ¸ëœ ë°ì´í„°ì…‹ì´ ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\\n{UPDATED_DATASET_PATH}\")\n",
        "print(\"ì´ì œ íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸ì˜ 'train_path'ë¥¼ ì´ ê²½ë¡œë¡œ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w88yiSN1uir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/images\"  # í™•ì¸í•  í´ë” ê²½ë¡œ\n",
        "count = sum(1 for f in os.listdir(folder_path) if f.lower().endswith(\".jpg\"))\n",
        "\n",
        "print(\"JPG íŒŒì¼ ê°œìˆ˜:\", count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I91sys325lDu"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "MYTEST_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_local.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(MYTEST_PATH)\n",
        "if \"input_type\" not in df.columns and \"input_tpye\" in df.columns:\n",
        "    df = df.rename(columns={\"input_tpye\": \"input_type\"})\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74NJuMCs6C0W"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "MYTEST_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(MYTEST_PATH)\n",
        "if \"input_type\" not in df.columns and \"input_tpye\" in df.columns:\n",
        "    df = df.rename(columns={\"input_tpye\": \"input_type\"})\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYR_vT9Y8G4r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ===============================================================\n",
        "# âš ï¸ ì„¤ì •: ìì‹ ì˜ í™˜ê²½ì— ë§ê²Œ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
        "# ===============================================================\n",
        "# ì›ë³¸ ì „ì²´ ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ\n",
        "ORIGINAL_TRAIN_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid.parquet\"\n",
        "\n",
        "# ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë”ê°€ ìƒì„±í•œ, URL ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬ëœ íŒŒì¼ ê²½ë¡œ\n",
        "PROCESSED_LOCAL_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_local.parquet\"\n",
        "\n",
        "# ìµœì¢…ì ìœ¼ë¡œ vqa ë°ì´í„°ê°€ í¬í•¨ë  íŒŒì¼ ê²½ë¡œ\n",
        "FINAL_TRAIN_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_final_with_vqa.parquet\"\n",
        "# ===============================================================\n",
        "\n",
        "print(\"ë°ì´í„° ë³‘í•©ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "# 1. ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ 'vqa' íƒœìŠ¤í¬ ë°ì´í„°ë§Œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "print(f\"'{ORIGINAL_TRAIN_PATH}'ì—ì„œ 'vqa' ë°ì´í„°ë¥¼ ì½ëŠ” ì¤‘...\")\n",
        "original_df = pd.read_parquet(ORIGINAL_TRAIN_PATH)\n",
        "vqa_df = original_df[original_df['task'] == 'vqa'].copy()\n",
        "print(f\"-> {len(vqa_df)}ê°œì˜ 'vqa' í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# 2. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë”ê°€ ì²˜ë¦¬í•œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "print(f\"'{PROCESSED_LOCAL_PATH}'ì—ì„œ ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œ ë°ì´í„°ë¥¼ ì½ëŠ” ì¤‘...\")\n",
        "local_df = pd.read_parquet(PROCESSED_LOCAL_PATH)\n",
        "print(f\"-> {len(local_df)}ê°œì˜ ì²˜ë¦¬ëœ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# 3. ë‘ ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸°\n",
        "print(\"ë‘ ë°ì´í„°ì…‹ì„ ë³‘í•©í•˜ëŠ” ì¤‘...\")\n",
        "final_df = pd.concat([local_df, vqa_df], ignore_index=True).sort_values(by='task')\n",
        "print(f\"-> ì´ {len(final_df)}ê°œì˜ í–‰ìœ¼ë¡œ ë³‘í•©ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# 4. ìµœì¢… ê²°ê³¼ë¬¼ ì €ì¥\n",
        "final_df.to_parquet(FINAL_TRAIN_PATH, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… ë°ì´í„° ë³‘í•© ì™„ë£Œ!\")\n",
        "print(f\"ìµœì¢… ë°ì´í„°ì…‹ì´ ë‹¤ìŒ ê²½ë¡œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\\n{FINAL_TRAIN_PATH}\")\n",
        "print(\"\\nì´ì œ íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸ì˜ 'train_path'ë¥¼ ì´ ìµœì¢… íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhplNSo-ABI6"
      },
      "outputs": [],
      "source": [
        "# ë³‘í•© í›„ ë°ì´í„° í†µê³„ í™•ì¸\n",
        "print(\"\\n[ë³‘í•© í›„ ë°ì´í„° í†µê³„]\")\n",
        "print(\"By task:\\n\", final_df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", final_df[\"input_type\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwIdo8EJW0GN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# âš ï¸ ì„¤ì •: ë³¸ì¸ í™˜ê²½ì˜ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-5018\"\n",
        "\n",
        "# Trainerê°€ ë¡œê·¸ë¥¼ ì €ì¥í•˜ëŠ” íŒŒì¼ ê²½ë¡œ\n",
        "log_history_path = os.path.join(output_dir, \"trainer_state.json\")\n",
        "\n",
        "try:\n",
        "    with open(log_history_path, \"r\") as f:\n",
        "        log_history = json.load(f)[\"log_history\"]\n",
        "\n",
        "    # ë³´ê¸° ì‰½ê²Œ DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "    df_log = pd.DataFrame(log_history)\n",
        "\n",
        "    print(\"âœ… í•™ìŠµ ë¡œê·¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    # í›ˆë ¨ ì†ì‹¤(loss)ê³¼ ê²€ì¦ ì†ì‹¤(eval_loss)ë§Œ í•„í„°ë§í•´ì„œ ë³´ê¸°\n",
        "    # dropna()ëŠ” í•´ë‹¹ ê°’ì´ ì—†ëŠ” í–‰(ì˜ˆ: í›ˆë ¨ ë¡œê·¸ì—ëŠ” eval_lossê°€ ì—†ìŒ)ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
        "    df_train_loss = df_log[['step', 'loss']].dropna()\n",
        "    df_eval_loss = df_log[['step', 'eval_loss']].dropna()\n",
        "\n",
        "    print(\"\\n--- í›ˆë ¨ ì†ì‹¤ (Training Loss) ---\")\n",
        "    print(df_train_loss.to_string(index=False))\n",
        "\n",
        "    print(\"\\n--- ê²€ì¦ ì†ì‹¤ (Validation Loss) ---\")\n",
        "    print(df_eval_loss.to_string(index=False))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ğŸš¨ ì˜¤ë¥˜: '{log_history_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "except (KeyError, IndexError):\n",
        "    print(\"ì•„ì§ ë¡œê·¸ ê¸°ë¡ì´ ì¶©ë¶„íˆ ìŒ“ì´ì§€ ì•Šì•˜ê±°ë‚˜ íŒŒì¼ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIM-Qj7_1-cU"
      },
      "outputs": [],
      "source": [
        "!rm -f /content/qwen25_vl_qlora_finetune.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# checkpoint ê²½ë¡œ\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-4000\"  # ë˜ëŠ” ì‚¬ìš©ì¤‘ì¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ\n",
        "\n",
        "# trainer_state.json ì½ê¸°\n",
        "state_path = os.path.join(checkpoint_dir, \"trainer_state.json\")\n",
        "with open(state_path, 'r') as f:\n",
        "    state = json.load(f)\n",
        "\n",
        "# í˜„ì¬ ì„¤ì • í™•ì¸\n",
        "print(\"Current settings in trainer_state.json:\")\n",
        "print(f\"  eval_steps: {state.get('eval_steps', 'not set')}\")\n",
        "print(f\"  save_steps: {state.get('save_steps', 'not set')}\")\n",
        "\n",
        "# ìˆ˜ì •\n",
        "state['eval_steps'] = 100\n",
        "state['save_steps'] = 100\n",
        "\n",
        "# ì €ì¥\n",
        "with open(state_path, 'w') as f:\n",
        "    json.dump(state, f, indent=2)\n",
        "\n",
        "print(\"\\nUpdated to:\")\n",
        "print(f\"  eval_steps: 100\")\n",
        "print(f\"  save_steps: 100\")"
      ],
      "metadata": {
        "id": "eyzkpeFsBSFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. image fine-tuning ì¤€ë¹„"
      ],
      "metadata": {
        "id": "XMn84xRqrn7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "IG_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/train_final.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(IG_PATH)\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "Jl_0XoPsry_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# captioning, vqa ë°ì´í„°ë§Œ í•„í„°ë§\n",
        "df_filtered = df[df[\"task\"].str.lower().isin([\"captioning\", \"vqa\"])]\n",
        "\n",
        "print(f\"Filtered rows: {len(df_filtered):,}\")\n",
        "print(df_filtered[\"task\"].value_counts())\n",
        "\n",
        "# ì €ì¥ (parquet & json)\n",
        "out_parquet = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_train.parquet\"\n",
        "out_json = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_train.json\"\n",
        "\n",
        "df_filtered.to_parquet(out_parquet, index=False)\n",
        "df_filtered.to_json(out_json, orient=\"records\", lines=True, force_ascii=False)\n",
        "\n",
        "print(f\"Saved parquet -> {out_parquet}\")\n",
        "print(f\"Saved json -> {out_json}\")"
      ],
      "metadata": {
        "id": "j4f9025Kr8Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "IMV_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_final.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(IMV_PATH)\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "tlymfVs3r9mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# captioning, vqa ë°ì´í„°ë§Œ í•„í„°ë§\n",
        "df_filtered = df[df[\"task\"].str.lower().isin([\"captioning\", \"vqa\"])]\n",
        "\n",
        "print(f\"Filtered rows: {len(df_filtered):,}\")\n",
        "print(df_filtered[\"task\"].value_counts())\n",
        "\n",
        "# ì €ì¥ (parquet & json)\n",
        "out_parquet = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_valid.parquet\"\n",
        "out_json = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_valid.json\"\n",
        "\n",
        "df_filtered.to_parquet(out_parquet, index=False)\n",
        "df_filtered.to_json(out_json, orient=\"records\", lines=True, force_ascii=False)\n",
        "\n",
        "print(f\"Saved parquet -> {out_parquet}\")\n",
        "print(f\"Saved json -> {out_json}\")"
      ],
      "metadata": {
        "id": "pjZpk3m3r9YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. LLM í•™ìŠµ"
      ],
      "metadata": {
        "id": "OsrXwiO2IhSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msiye9Ca5QL1"
      },
      "outputs": [],
      "source": [
        "!wget -O llm_finetune.py https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/llm_finetune.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxAtOOqATeda"
      },
      "outputs": [],
      "source": [
        "from llm_finetune import train\n",
        "\n",
        "adapter_dir = train(\n",
        "    base_model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
        "    train_path=\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/train_final.parquet\",\n",
        "    valid_path=\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_final.parquet\",\n",
        "    out_dir=\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out\",\n",
        "    profile=\"dev\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. projector í•™ìŠµ (ì´ë¯¸ì§€ ì¦ê°•ì€ ì ìš© ì•ˆí–ˆìŒ)"
      ],
      "metadata": {
        "id": "e1BkI8WrIajh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# ì¦ê°• í™•ì¸ í•¨ìˆ˜\n",
        "def test_augmentation(train_path, num_samples=3):\n",
        "    \"\"\"\n",
        "    Captioningê³¼ VQA íƒœìŠ¤í¬ì˜ ì¦ê°• ì „í›„ ë¹„êµ\n",
        "    \"\"\"\n",
        "    # ë°ì´í„° ë¡œë“œ\n",
        "    df = pd.read_parquet(train_path)\n",
        "\n",
        "    # íƒœìŠ¤í¬ë³„ë¡œ ìƒ˜í”Œ ì„ íƒ\n",
        "    captioning_samples = df[df['task'].str.contains('caption', case=False)].sample(min(num_samples, len(df)))\n",
        "    vqa_samples = df[df['task'].str.contains('vqa|question', case=False)].sample(min(num_samples, len(df)))\n",
        "\n",
        "    # Augmentor ìƒì„±\n",
        "    augmentor = ImageAugmentor()\n",
        "\n",
        "    # Figure ì„¤ì •\n",
        "    fig, axes = plt.subplots(num_samples * 2, 4, figsize=(16, num_samples * 8))\n",
        "    fig.suptitle('Image Augmentation Test: Captioning vs VQA', fontsize=16)\n",
        "\n",
        "    row = 0\n",
        "\n",
        "    # Captioning ìƒ˜í”Œ ì²˜ë¦¬\n",
        "    print(\"=\" * 60)\n",
        "    print(\"CAPTIONING SAMPLES (Strong Augmentation)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for idx, (_, sample) in enumerate(captioning_samples.iterrows()):\n",
        "        print(f\"\\nCaptioning Sample {idx+1}:\")\n",
        "        print(f\"Task: {sample['task']}\")\n",
        "        print(f\"Output: {sample['output'][:100]}...\")\n",
        "\n",
        "        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        try:\n",
        "            original_img = load_image_strict(sample['input'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "            continue\n",
        "\n",
        "        # ì¦ê°• 3ë²ˆ ì ìš©\n",
        "        augmented_imgs = []\n",
        "        for _ in range(3):\n",
        "            aug_img = augmentor.augment(original_img.copy(), sample['task'])\n",
        "            augmented_imgs.append(aug_img)\n",
        "\n",
        "        # ì‹œê°í™”\n",
        "        axes[row, 0].imshow(original_img)\n",
        "        axes[row, 0].set_title(f'Original (Caption {idx+1})', fontsize=10)\n",
        "        axes[row, 0].axis('off')\n",
        "\n",
        "        for j, aug_img in enumerate(augmented_imgs):\n",
        "            axes[row, j+1].imshow(aug_img)\n",
        "            axes[row, j+1].set_title(f'Augmented {j+1}', fontsize=10)\n",
        "            axes[row, j+1].axis('off')\n",
        "\n",
        "        row += 1\n",
        "\n",
        "    # VQA ìƒ˜í”Œ ì²˜ë¦¬\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"VQA SAMPLES (Minimal Augmentation)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for idx, (_, sample) in enumerate(vqa_samples.iterrows()):\n",
        "        print(f\"\\nVQA Sample {idx+1}:\")\n",
        "        print(f\"Task: {sample['task']}\")\n",
        "        print(f\"Question: {sample.get('question', 'N/A')}\")\n",
        "        print(f\"Answer: {sample['output'][:100]}...\")\n",
        "\n",
        "        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        try:\n",
        "            original_img = load_image_strict(sample['input'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "            continue\n",
        "\n",
        "        # ì¦ê°• 3ë²ˆ ì ìš©\n",
        "        augmented_imgs = []\n",
        "        for _ in range(3):\n",
        "            aug_img = augmentor.augment(original_img.copy(), sample['task'])\n",
        "            augmented_imgs.append(aug_img)\n",
        "\n",
        "        # ì‹œê°í™”\n",
        "        axes[row, 0].imshow(original_img)\n",
        "        axes[row, 0].set_title(f'Original (VQA {idx+1})', fontsize=10)\n",
        "        axes[row, 0].axis('off')\n",
        "\n",
        "        for j, aug_img in enumerate(augmented_imgs):\n",
        "            axes[row, j+1].imshow(aug_img)\n",
        "            axes[row, j+1].set_title(f'Augmented {j+1}', fontsize=10)\n",
        "            axes[row, j+1].axis('off')\n",
        "\n",
        "        row += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "# ì¦ê°• ì°¨ì´ ì •ëŸ‰ì  ë¶„ì„\n",
        "def analyze_augmentation_difference(train_path):\n",
        "    \"\"\"\n",
        "    ì¦ê°• ê°•ë„ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„\n",
        "    \"\"\"\n",
        "    df = pd.read_parquet(train_path)\n",
        "    augmentor = ImageAugmentor()\n",
        "\n",
        "    results = {\n",
        "        'captioning': {'pixel_diff': [], 'color_diff': []},\n",
        "        'vqa': {'pixel_diff': [], 'color_diff': []}\n",
        "    }\n",
        "\n",
        "    # ê° íƒœìŠ¤í¬ë³„ë¡œ 10ê°œ ìƒ˜í”Œ ë¶„ì„\n",
        "    for task_type in ['caption', 'vqa']:\n",
        "        samples = df[df['task'].str.contains(task_type, case=False)].head(10)\n",
        "\n",
        "        for _, sample in samples.iterrows():\n",
        "            try:\n",
        "                # ì›ë³¸ ì´ë¯¸ì§€\n",
        "                original = load_image_strict(sample['input'])\n",
        "                original_array = np.array(original)\n",
        "\n",
        "                # ì¦ê°• ì´ë¯¸ì§€\n",
        "                augmented = augmentor.augment(original.copy(), sample['task'])\n",
        "                augmented_array = np.array(augmented)\n",
        "\n",
        "                # í”½ì…€ ì°¨ì´ ê³„ì‚°\n",
        "                pixel_diff = np.mean(np.abs(original_array - augmented_array))\n",
        "\n",
        "                # ìƒ‰ìƒ íˆìŠ¤í† ê·¸ë¨ ì°¨ì´\n",
        "                orig_hist = np.histogram(original_array, bins=256)[0]\n",
        "                aug_hist = np.histogram(augmented_array, bins=256)[0]\n",
        "                color_diff = np.sum(np.abs(orig_hist - aug_hist))\n",
        "\n",
        "                task_key = 'captioning' if 'caption' in task_type else 'vqa'\n",
        "                results[task_key]['pixel_diff'].append(pixel_diff)\n",
        "                results[task_key]['color_diff'].append(color_diff)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sample: {e}\")\n",
        "                continue\n",
        "\n",
        "    # ê²°ê³¼ ì¶œë ¥\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"AUGMENTATION STRENGTH ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for task in results:\n",
        "        if results[task]['pixel_diff']:\n",
        "            avg_pixel = np.mean(results[task]['pixel_diff'])\n",
        "            avg_color = np.mean(results[task]['color_diff'])\n",
        "\n",
        "            print(f\"\\n{task.upper()}:\")\n",
        "            print(f\"  Average Pixel Difference: {avg_pixel:.2f}\")\n",
        "            print(f\"  Average Color Histogram Difference: {avg_color:.2f}\")\n",
        "\n",
        "            # ì¦ê°• ê°•ë„ íŒì •\n",
        "            if avg_pixel < 5:\n",
        "                strength = \"Very Weak\"\n",
        "            elif avg_pixel < 15:\n",
        "                strength = \"Weak\"\n",
        "            elif avg_pixel < 30:\n",
        "                strength = \"Moderate\"\n",
        "            else:\n",
        "                strength = \"Strong\"\n",
        "\n",
        "            print(f\"  Augmentation Strength: {strength}\")\n",
        "\n",
        "    # ì‹œê°í™”\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Pixel difference ë¹„êµ\n",
        "    axes[0].bar(['Captioning', 'VQA'],\n",
        "                [np.mean(results['captioning']['pixel_diff']),\n",
        "                 np.mean(results['vqa']['pixel_diff'])])\n",
        "    axes[0].set_title('Average Pixel Difference')\n",
        "    axes[0].set_ylabel('Pixel Difference')\n",
        "\n",
        "    # Color difference ë¹„êµ\n",
        "    axes[1].bar(['Captioning', 'VQA'],\n",
        "                [np.mean(results['captioning']['color_diff']),\n",
        "                 np.mean(results['vqa']['color_diff'])])\n",
        "    axes[1].set_title('Average Color Histogram Difference')\n",
        "    axes[1].set_ylabel('Histogram Difference')\n",
        "\n",
        "    plt.suptitle('Augmentation Strength Comparison: Captioning vs VQA')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ë‹¨ì¼ ì´ë¯¸ì§€ ì¦ê°• í…ŒìŠ¤íŠ¸\n",
        "def test_single_augmentation(image_path, task=\"captioning\"):\n",
        "    \"\"\"\n",
        "    ë‹¨ì¼ ì´ë¯¸ì§€ë¡œ ì¦ê°• í…ŒìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    augmentor = ImageAugmentor()\n",
        "\n",
        "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # 6ë²ˆ ì¦ê°•\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    fig.suptitle(f'Single Image Augmentation Test - Task: {task}', fontsize=14)\n",
        "\n",
        "    # ì›ë³¸\n",
        "    axes[0, 0].imshow(img)\n",
        "    axes[0, 0].set_title('Original')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # ì¦ê°• 7ë²ˆ\n",
        "    positions = [(0, 1), (0, 2), (0, 3), (1, 0), (1, 1), (1, 2), (1, 3)]\n",
        "    for i, (row, col) in enumerate(positions):\n",
        "        aug_img = augmentor.augment(img.copy(), task)\n",
        "        axes[row, col].imshow(aug_img)\n",
        "        axes[row, col].set_title(f'Augmented {i+1}')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ì‹¤í–‰ ì˜ˆì‹œ\n",
        "if __name__ == \"__main__\":\n",
        "    train_path = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_train.parquet\"\n",
        "\n",
        "    # 1. ì¦ê°• ì‹œê°í™” í…ŒìŠ¤íŠ¸\n",
        "    print(\"Testing augmentation on samples...\")\n",
        "    fig = test_augmentation(train_path, num_samples=3)\n",
        "\n",
        "    # 2. ì¦ê°• ê°•ë„ ë¶„ì„\n",
        "    print(\"\\nAnalyzing augmentation strength...\")\n",
        "    analyze_augmentation_difference(train_path)\n",
        "\n",
        "    # 3. ì €ì¥ (ì„ íƒì‚¬í•­)\n",
        "    fig.savefig('/content/drive/MyDrive/Colab Notebooks/wook/augmentation_test.png', dpi=150, bbox_inches='tight')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6neVeczmonlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Step 1: ì²´í¬í¬ì¸íŠ¸ ë°±ì—…\n",
        "checkpoint_4000 = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-4000\"\n",
        "backup_path = checkpoint_4000 + \"_backup\"\n",
        "\n",
        "if not os.path.exists(backup_path):\n",
        "    shutil.copytree(checkpoint_4000, backup_path)\n",
        "    print(f\"Backup created: {backup_path}\")\n",
        "\n",
        "# Step 2: optimizer.pt ì œê±° (ì¶©ëŒ ë°©ì§€)\n",
        "optimizer_path = os.path.join(checkpoint_4000, \"optimizer.pt\")\n",
        "if os.path.exists(optimizer_path):\n",
        "    os.remove(optimizer_path)\n",
        "    print(\"Removed optimizer.pt\")\n",
        "\n",
        "# Step 3: trainer_state.json ìˆ˜ì •\n",
        "import json\n",
        "state_path = os.path.join(checkpoint_4000, \"trainer_state.json\")\n",
        "if os.path.exists(state_path):\n",
        "    with open(state_path, 'r') as f:\n",
        "        state = json.load(f)\n",
        "\n",
        "    # ì„¤ì • ì—…ë°ì´íŠ¸\n",
        "    state['eval_steps'] = 500\n",
        "    state['save_steps'] = 500\n",
        "    state['learning_rate'] = 3e-5\n",
        "\n",
        "    with open(state_path, 'w') as f:\n",
        "        json.dump(state, f, indent=2)\n",
        "    print(\"Updated trainer_state.json\")"
      ],
      "metadata": {
        "id": "SzR16Q8s8Rt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495021a1-ac7a-45f8-d931-a9ea27c8b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backup created: /content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-4000_backup\n",
            "Updated trainer_state.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O projector_finetune.py https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/projector_finetune.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR_eXlLguNBV",
        "outputId": "cb927ae3-805d-48c5-f3e3-5be090a4e764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-25 10:31:14--  https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/projector_finetune.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27026 (26K) [text/plain]\n",
            "Saving to: â€˜projector_finetune.pyâ€™\n",
            "\n",
            "\rprojector_finetune.   0%[                    ]       0  --.-KB/s               \rprojector_finetune. 100%[===================>]  26.39K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-08-25 10:31:14 (10.4 MB/s) - â€˜projector_finetune.pyâ€™ saved [27026/27026]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWsFzItB5pFr",
        "outputId": "aba92e23-b20a-48b1-8cfc-a8793b0353bf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.46 in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Collecting transformers>=4.46\n",
            "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.34 in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Requirement already satisfied: peft>=0.11 in /usr/local/lib/python3.12/dist-packages (0.17.0)\n",
            "Collecting peft>=0.11\n",
            "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34) (2.8.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46) (1.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34) (3.0.2)\n",
            "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, scikit-learn, pandas, transformers, bitsandbytes, peft\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.2\n",
            "    Uninstalling transformers-4.55.2:\n",
            "      Successfully uninstalled transformers-4.55.2\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.0\n",
            "    Uninstalling peft-0.17.0:\n",
            "      Successfully uninstalled peft-0.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.47.0 pandas-2.3.2 peft-0.17.1 requests-2.32.5 scikit-learn-1.7.1 transformers-4.55.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"transformers>=4.46\" \"accelerate>=0.34\" \"peft>=0.11\" bitsandbytes pandas pillow requests scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O llm_projector_finetune.py https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/llm_projector_finetune.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-J3X8VaoG0y",
        "outputId": "affca7b8-9339-43f8-9d24-e1e84ad9862b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-25 10:55:01--  https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/llm_projector_finetune.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26002 (25K) [text/plain]\n",
            "Saving to: â€˜llm_projector_finetune.pyâ€™\n",
            "\n",
            "llm_projector_finet 100%[===================>]  25.39K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-08-25 10:55:01 (9.32 MB/s) - â€˜llm_projector_finetune.pyâ€™ saved [26002/26002]\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}