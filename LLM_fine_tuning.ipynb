{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQj9vG-8Cl-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb401979-fd05-42bf-a3ee-c1f198af0ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bitsandbytes version: 0.47.0\n",
            "transformers version: 4.55.4\n"
          ]
        }
      ],
      "source": [
        "import bitsandbytes as bnb\n",
        "import transformers\n",
        "\n",
        "print(\"bitsandbytes version:\", bnb.__version__)\n",
        "print(\"transformers version:\", transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bft7haCVyEYU"
      },
      "outputs": [],
      "source": [
        "import os, io\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from urllib.request import Request, urlopen\n",
        "from urllib.parse import urlparse\n",
        "from urllib.error import URLError, HTTPError\n",
        "\n",
        "# ===== 설정 =====\n",
        "inputs_file = \"/content/drive/MyDrive/Colab Notebooks/wook/deeplearningchallenge/deep_chal_multitask_dataset.parquet\"\n",
        "URL_TIMEOUT = 20\n",
        "\n",
        "# ===== 유틸 =====\n",
        "def is_url(s: str) -> bool:\n",
        "    try:\n",
        "        return urlparse(str(s)).scheme in (\"http\", \"https\")\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def is_valid_image_url(u: str, timeout: int = URL_TIMEOUT) -> bool:\n",
        "    \"\"\"URL이 존재하고, 실제 이미지로 디코딩 가능한지 점검\"\"\"\n",
        "    try:\n",
        "        req = Request(u, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        with urlopen(req, timeout=timeout) as r:\n",
        "            raw = r.read()\n",
        "        if len(raw) < 32:\n",
        "            return False\n",
        "        # 손상 파일/HTML 응답 걸러내기\n",
        "        bio = io.BytesIO(raw)\n",
        "        Image.open(bio).verify()   # 포맷/무결성 점검\n",
        "        # 재오픈해서 실제 디코딩 가능한지도 확인\n",
        "        Image.open(io.BytesIO(raw)).convert(\"RGB\")\n",
        "        return True\n",
        "    except (HTTPError, URLError, TimeoutError, Image.UnidentifiedImageError):\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# ===== 로드 =====\n",
        "df = pd.read_parquet(inputs_file)\n",
        "n_total = len(df)\n",
        "\n",
        "# 컬럼 존재 체크\n",
        "for col in (\"input_type\", \"input\"):\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"'{col}' column is required, but not found in the dataset.\")\n",
        "\n",
        "# URL 이미지 행만 타깃팅\n",
        "mask_image = df[\"input_type\"].astype(str).str.lower().eq(\"image\")\n",
        "mask_url   = df[\"input\"].astype(str).apply(is_url)\n",
        "target_idx = df[mask_image & mask_url].index\n",
        "\n",
        "# 점검 & 제거 목록 수집\n",
        "bad_idx = []\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except Exception:\n",
        "    def tqdm(x, **k): return x\n",
        "\n",
        "for i in tqdm(target_idx, total=len(target_idx), desc=\"Checking image URLs\"):\n",
        "    u = str(df.at[i, \"input\"])\n",
        "    if not is_valid_image_url(u):\n",
        "        bad_idx.append(i)\n",
        "\n",
        "# 제거 및 저장\n",
        "clean_df = df.drop(index=bad_idx).reset_index(drop=True)\n",
        "\n",
        "base_dir, base_name = os.path.split(inputs_file)\n",
        "stem = os.path.splitext(base_name)[0]\n",
        "out_path = os.path.join(base_dir, f\"{stem}_clean.parquet\")\n",
        "clean_df.to_parquet(out_path, index=False)\n",
        "\n",
        "# 리포트\n",
        "print(\"=== URL 이미지 정리 결과 ===\")\n",
        "print(f\"총 행         : {n_total}\")\n",
        "print(f\"URL 이미지 행 : {len(target_idx)}\")\n",
        "print(f\"제거된 행     : {len(bad_idx)}\")\n",
        "print(f\"남은 행       : {len(clean_df)}\")\n",
        "print(f\"저장 경로     : {out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNdsQ9_G87z9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "# 이미 세션에 존재한다고 가정: df (원본 DataFrame), bad_idx (제거 대상 인덱스 리스트)\n",
        "assert 'df' in globals(), \"df가 세션에 없습니다.\"\n",
        "assert 'bad_idx' in globals(), \"bad_idx가 세션에 없습니다.\"\n",
        "\n",
        "# 1) 제거 인덱스 5개 미리보기\n",
        "print(\"=== 제거 인덱스 미리보기(5) ===\")\n",
        "preview_idx = bad_idx[:5]\n",
        "print(preview_idx)\n",
        "\n",
        "# 2) 해당 인덱스의 URL 5개 확인\n",
        "print(\"\\n=== 제거된 행의 URL(5) ===\")\n",
        "preview_urls = df.loc[preview_idx, \"input\"].astype(str).tolist()\n",
        "for i, u in enumerate(preview_urls, 1):\n",
        "    print(f\"{i}. {u}\")\n",
        "\n",
        "# 3) 전체 제거 인덱스/URL 저장 (원본 parquet와 같은 위치에)\n",
        "inputs_file = \"/content/drive/MyDrive/Colab Notebooks/wook/deeplearningchallenge/deep_chal_multitask_dataset.parquet\"\n",
        "base_dir, base_name = os.path.split(inputs_file)\n",
        "stem = os.path.splitext(base_name)[0]\n",
        "\n",
        "idx_json = os.path.join(base_dir, f\"{stem}_removed_indices.json\")\n",
        "with open(idx_json, \"w\") as f:\n",
        "    json.dump(list(map(int, bad_idx)), f)\n",
        "print(f\"\\n[저장] 제거 인덱스 JSON: {idx_json}\")\n",
        "\n",
        "idx_csv = os.path.join(base_dir, f\"{stem}_removed_indices.csv\")\n",
        "pd.DataFrame({\n",
        "    \"index\": list(map(int, bad_idx)),\n",
        "    \"input\": df.loc[bad_idx, \"input\"].astype(str).values\n",
        "}).to_csv(idx_csv, index=False)\n",
        "print(f\"[저장] 제거 인덱스+URL CSV: {idx_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlJGNdCLHQMW"
      },
      "source": [
        "1. 데이터 분할(trian, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FERVmpLh_cvW"
      },
      "outputs": [],
      "source": [
        "from qlora_vl_qwen_25 import build_train_valid\n",
        "\n",
        "OUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning\"\n",
        "\n",
        "# 1) 분할 (라벨 포함 파일이므로 labels_file=None)\n",
        "train_df, valid_df = build_train_valid(\n",
        "    out_root=OUT_DIR,\n",
        "    inputs_file=\"/content/drive/MyDrive/Colab Notebooks/wook/deeplearningchallenge/deep_chal_multitask_dataset_clean.parquet\",\n",
        "    labels_file=None,\n",
        "    valid_ratio=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMkw5tQ9HUpg"
      },
      "source": [
        "2. LLM fine-tuning 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHYGX6g18KsM"
      },
      "outputs": [],
      "source": [
        "import importlib, qlora_vl_qwen_25 as m\n",
        "import torch\n",
        "\n",
        "m.IMG_BASE = \"/content\"  # 상대경로 쓰면 맞춰주세요\n",
        "OUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning\"\n",
        "\n",
        "m.train_model(\n",
        "    base_model=m.DEFAULT_BASE_MODEL,\n",
        "    train_file=f\"{OUT_DIR}/datasets/qlora/train.parquet\",\n",
        "    valid_file=f\"{OUT_DIR}/datasets/qlora/valid.parquet\",\n",
        "    out_root=OUT_DIR,\n",
        "    profile=\"balanced\",\n",
        "    add_task_hint=True,\n",
        "    lora_r=64, lora_alpha=128, lora_dropout=0.05,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQfJ-CicwdJz"
      },
      "outputs": [],
      "source": [
        "from urllib.request import Request, urlopen\n",
        "from urllib.error import HTTPError, URLError\n",
        "\n",
        "URL_TIMEOUT = 10\n",
        "url = \"https://pulpcovers.com/wp-content/uploads/2012/01/36591544-6652526511_fe9af8fcd6_o1.jpg\"\n",
        "\n",
        "try:\n",
        "    req = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "    with urlopen(req, timeout=URL_TIMEOUT) as r:\n",
        "        print(\"Response status:\", r.status)\n",
        "        content_length = len(r.read())\n",
        "        print(\"Downloaded bytes:\", content_length)\n",
        "except HTTPError as e:\n",
        "    print(\"HTTPError:\", e.code, e.reason)\n",
        "except URLError as e:\n",
        "    print(\"URLError:\", e.reason)\n",
        "except Exception as e:\n",
        "    print(\"Other Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDIMujKP1CdP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from PIL import Image\n",
        "import os\n",
        "import io\n",
        "from tqdm.auto import tqdm\n",
        "from urllib.parse import urlparse\n",
        "import warnings\n",
        "\n",
        "# ===============================================================\n",
        "# ⚠️ 설정: 자신의 환경에 맞게 이 부분을 수정하세요.\n",
        "# ===============================================================\n",
        "# 원본 데이터셋 파일 경로\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid.parquet\"\n",
        "\n",
        "# 다운로드한 이미지를 저장할 구글 드라이브 폴더 경로\n",
        "IMAGE_SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/images_v\"\n",
        "# ===============================================================\n",
        "\n",
        "# 저장할 디렉토리 생성\n",
        "os.makedirs(IMAGE_SAVE_DIR, exist_ok=True)\n",
        "print(f\"이미지를 저장할 경로: {IMAGE_SAVE_DIR}\")\n",
        "\n",
        "df = pd.read_parquet(DATASET_PATH)\n",
        "image_rows = df[df['input_type'] == 'image'].copy()\n",
        "print(f\"총 {len(image_rows)}개의 이미지를 다운로드합니다.\")\n",
        "\n",
        "downloaded_paths = []\n",
        "\n",
        "for index, row in tqdm(image_rows.iterrows(), total=len(image_rows), desc=\"이미지 다운로드 중\"):\n",
        "    url = row['input']\n",
        "    try:\n",
        "        # URL에서 파일 이름 추출\n",
        "        parsed_url = urlparse(url)\n",
        "        # 고유한 파일명을 위해 인덱스와 원본 파일명을 조합\n",
        "        filename = f\"{index}_{os.path.basename(parsed_url.path)}\"\n",
        "        save_path = os.path.join(IMAGE_SAVE_DIR, filename)\n",
        "\n",
        "        # 이미 파일이 존재하면 다운로드 건너뛰기\n",
        "        if os.path.exists(save_path):\n",
        "            downloaded_paths.append(save_path)\n",
        "            continue\n",
        "\n",
        "        response = requests.get(url, timeout=20, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        response.raise_for_status() # HTTP 에러가 있으면 예외 발생\n",
        "\n",
        "        # 이미지가 유효한지 확인\n",
        "        img = Image.open(io.BytesIO(response.content))\n",
        "        img.verify() # 이미지 데이터 유효성 검사\n",
        "\n",
        "        # 유효하면 파일로 저장\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        downloaded_paths.append(save_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        warnings.warn(f\"다운로드 실패 (인덱스: {index}, URL: {url}): {e}\")\n",
        "        downloaded_paths.append(None) # 실패한 경우 None으로 표시\n",
        "\n",
        "# 원본 데이터프레임의 'input' 열을 다운로드된 로컬 경로로 업데이트\n",
        "image_rows['input'] = downloaded_paths\n",
        "\n",
        "# 이미지가 아닌 데이터와 다시 합치기\n",
        "non_image_rows = df[df['input_type'] != 'image']\n",
        "updated_df = pd.concat([non_image_rows, image_rows]).sort_index()\n",
        "\n",
        "# 다운로드에 실패한 데이터는 제외\n",
        "updated_df.dropna(subset=['input'], inplace=True)\n",
        "\n",
        "# 수정된 데이터셋을 새 파일로 저장\n",
        "UPDATED_DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_local.parquet\"\n",
        "updated_df.to_parquet(UPDATED_DATASET_PATH, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✅ 이미지 다운로드 및 데이터셋 업데이트 완료!\")\n",
        "print(f\"업데이트된 데이터셋이 다음 경로에 저장되었습니다:\\n{UPDATED_DATASET_PATH}\")\n",
        "print(\"이제 파인튜닝 스크립트의 'train_path'를 이 경로로 변경하여 사용하세요.\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w88yiSN1uir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/images\"  # 확인할 폴더 경로\n",
        "count = sum(1 for f in os.listdir(folder_path) if f.lower().endswith(\".jpg\"))\n",
        "\n",
        "print(\"JPG 파일 개수:\", count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I91sys325lDu"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "MYTEST_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_local.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(MYTEST_PATH)\n",
        "if \"input_type\" not in df.columns and \"input_tpye\" in df.columns:\n",
        "    df = df.rename(columns={\"input_tpye\": \"input_type\"})\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74NJuMCs6C0W"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "MYTEST_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(MYTEST_PATH)\n",
        "if \"input_type\" not in df.columns and \"input_tpye\" in df.columns:\n",
        "    df = df.rename(columns={\"input_tpye\": \"input_type\"})\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYR_vT9Y8G4r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ===============================================================\n",
        "# ⚠️ 설정: 자신의 환경에 맞게 파일 경로를 확인하세요.\n",
        "# ===============================================================\n",
        "# 원본 전체 데이터셋 파일 경로\n",
        "ORIGINAL_TRAIN_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid.parquet\"\n",
        "\n",
        "# 이미지 다운로더가 생성한, URL 이미지만 처리된 파일 경로\n",
        "PROCESSED_LOCAL_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_local.parquet\"\n",
        "\n",
        "# 최종적으로 vqa 데이터가 포함될 파일 경로\n",
        "FINAL_TRAIN_PATH = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_final_with_vqa.parquet\"\n",
        "# ===============================================================\n",
        "\n",
        "print(\"데이터 병합을 시작합니다...\")\n",
        "\n",
        "# 1. 원본 데이터셋에서 'vqa' 태스크 데이터만 불러오기\n",
        "print(f\"'{ORIGINAL_TRAIN_PATH}'에서 'vqa' 데이터를 읽는 중...\")\n",
        "original_df = pd.read_parquet(ORIGINAL_TRAIN_PATH)\n",
        "vqa_df = original_df[original_df['task'] == 'vqa'].copy()\n",
        "print(f\"-> {len(vqa_df)}개의 'vqa' 행을 찾았습니다.\")\n",
        "\n",
        "# 2. 이미지 다운로더가 처리한 데이터 불러오기\n",
        "print(f\"'{PROCESSED_LOCAL_PATH}'에서 로컬 이미지 경로 데이터를 읽는 중...\")\n",
        "local_df = pd.read_parquet(PROCESSED_LOCAL_PATH)\n",
        "print(f\"-> {len(local_df)}개의 처리된 행을 찾았습니다.\")\n",
        "\n",
        "# 3. 두 데이터프레임 합치기\n",
        "print(\"두 데이터셋을 병합하는 중...\")\n",
        "final_df = pd.concat([local_df, vqa_df], ignore_index=True).sort_values(by='task')\n",
        "print(f\"-> 총 {len(final_df)}개의 행으로 병합되었습니다.\")\n",
        "\n",
        "# 4. 최종 결과물 저장\n",
        "final_df.to_parquet(FINAL_TRAIN_PATH, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✅ 데이터 병합 완료!\")\n",
        "print(f\"최종 데이터셋이 다음 경로에 저장되었습니다:\\n{FINAL_TRAIN_PATH}\")\n",
        "print(\"\\n이제 파인튜닝 스크립트의 'train_path'를 이 최종 파일 경로로 변경하여 사용하세요.\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhplNSo-ABI6"
      },
      "outputs": [],
      "source": [
        "# 병합 후 데이터 통계 확인\n",
        "print(\"\\n[병합 후 데이터 통계]\")\n",
        "print(\"By task:\\n\", final_df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", final_df[\"input_type\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwIdo8EJW0GN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ⚠️ 설정: 본인 환경의 경로로 수정해주세요.\n",
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-5018\"\n",
        "\n",
        "# Trainer가 로그를 저장하는 파일 경로\n",
        "log_history_path = os.path.join(output_dir, \"trainer_state.json\")\n",
        "\n",
        "try:\n",
        "    with open(log_history_path, \"r\") as f:\n",
        "        log_history = json.load(f)[\"log_history\"]\n",
        "\n",
        "    # 보기 쉽게 DataFrame으로 변환\n",
        "    df_log = pd.DataFrame(log_history)\n",
        "\n",
        "    print(\"✅ 학습 로그를 성공적으로 불러왔습니다.\")\n",
        "\n",
        "    # 훈련 손실(loss)과 검증 손실(eval_loss)만 필터링해서 보기\n",
        "    # dropna()는 해당 값이 없는 행(예: 훈련 로그에는 eval_loss가 없음)을 제거합니다.\n",
        "    df_train_loss = df_log[['step', 'loss']].dropna()\n",
        "    df_eval_loss = df_log[['step', 'eval_loss']].dropna()\n",
        "\n",
        "    print(\"\\n--- 훈련 손실 (Training Loss) ---\")\n",
        "    print(df_train_loss.to_string(index=False))\n",
        "\n",
        "    print(\"\\n--- 검증 손실 (Validation Loss) ---\")\n",
        "    print(df_eval_loss.to_string(index=False))\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"🚨 오류: '{log_history_path}' 파일을 찾을 수 없습니다. 경로를 다시 확인해주세요.\")\n",
        "except (KeyError, IndexError):\n",
        "    print(\"아직 로그 기록이 충분히 쌓이지 않았거나 파일에 문제가 있습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIM-Qj7_1-cU"
      },
      "outputs": [],
      "source": [
        "!rm -f /content/qwen25_vl_qlora_finetune.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# checkpoint 경로\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-4000\"  # 또는 사용중인 체크포인트 경로\n",
        "\n",
        "# trainer_state.json 읽기\n",
        "state_path = os.path.join(checkpoint_dir, \"trainer_state.json\")\n",
        "with open(state_path, 'r') as f:\n",
        "    state = json.load(f)\n",
        "\n",
        "# 현재 설정 확인\n",
        "print(\"Current settings in trainer_state.json:\")\n",
        "print(f\"  eval_steps: {state.get('eval_steps', 'not set')}\")\n",
        "print(f\"  save_steps: {state.get('save_steps', 'not set')}\")\n",
        "\n",
        "# 수정\n",
        "state['eval_steps'] = 100\n",
        "state['save_steps'] = 100\n",
        "\n",
        "# 저장\n",
        "with open(state_path, 'w') as f:\n",
        "    json.dump(state, f, indent=2)\n",
        "\n",
        "print(\"\\nUpdated to:\")\n",
        "print(f\"  eval_steps: 100\")\n",
        "print(f\"  save_steps: 100\")"
      ],
      "metadata": {
        "id": "eyzkpeFsBSFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. image fine-tuning 준비"
      ],
      "metadata": {
        "id": "XMn84xRqrn7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "IG_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/train_final.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(IG_PATH)\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "Jl_0XoPsry_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# captioning, vqa 데이터만 필터링\n",
        "df_filtered = df[df[\"task\"].str.lower().isin([\"captioning\", \"vqa\"])]\n",
        "\n",
        "print(f\"Filtered rows: {len(df_filtered):,}\")\n",
        "print(df_filtered[\"task\"].value_counts())\n",
        "\n",
        "# 저장 (parquet & json)\n",
        "out_parquet = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_train.parquet\"\n",
        "out_json = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_train.json\"\n",
        "\n",
        "df_filtered.to_parquet(out_parquet, index=False)\n",
        "df_filtered.to_json(out_json, orient=\"records\", lines=True, force_ascii=False)\n",
        "\n",
        "print(f\"Saved parquet -> {out_parquet}\")\n",
        "print(f\"Saved json -> {out_json}\")"
      ],
      "metadata": {
        "id": "j4f9025Kr8Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Load data & Run\n",
        "# ==========================\n",
        "IMV_PATH = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_final.parquet\")\n",
        "# Load df\n",
        "df = pd.read_parquet(IMV_PATH)\n",
        "df = df.reset_index(drop=True)\n",
        "df.insert(0, \"id\", df.index.astype(str))\n",
        "\n",
        "# Quick stats\n",
        "print(f\"Total rows: {len(df):,}\")\n",
        "print(\"\\nBy task:\\n\", df[\"task\"].str.lower().value_counts(dropna=False))\n",
        "print(\"\\nBy input_type:\\n\", df[\"input_type\"].str.lower().value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "tlymfVs3r9mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# captioning, vqa 데이터만 필터링\n",
        "df_filtered = df[df[\"task\"].str.lower().isin([\"captioning\", \"vqa\"])]\n",
        "\n",
        "print(f\"Filtered rows: {len(df_filtered):,}\")\n",
        "print(df_filtered[\"task\"].value_counts())\n",
        "\n",
        "# 저장 (parquet & json)\n",
        "out_parquet = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_valid.parquet\"\n",
        "out_json = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_valid.json\"\n",
        "\n",
        "df_filtered.to_parquet(out_parquet, index=False)\n",
        "df_filtered.to_json(out_json, orient=\"records\", lines=True, force_ascii=False)\n",
        "\n",
        "print(f\"Saved parquet -> {out_parquet}\")\n",
        "print(f\"Saved json -> {out_json}\")"
      ],
      "metadata": {
        "id": "pjZpk3m3r9YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. LLM 학습"
      ],
      "metadata": {
        "id": "OsrXwiO2IhSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msiye9Ca5QL1"
      },
      "outputs": [],
      "source": [
        "!wget -O llm_finetune.py https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/llm_finetune.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxAtOOqATeda"
      },
      "outputs": [],
      "source": [
        "from llm_finetune import train\n",
        "\n",
        "adapter_dir = train(\n",
        "    base_model=\"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
        "    train_path=\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/train_final.parquet\",\n",
        "    valid_path=\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/valid_final.parquet\",\n",
        "    out_dir=\"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out\",\n",
        "    profile=\"dev\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. projector 학습 (이미지 증강은 적용 안했음)"
      ],
      "metadata": {
        "id": "e1BkI8WrIajh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# 증강 확인 함수\n",
        "def test_augmentation(train_path, num_samples=3):\n",
        "    \"\"\"\n",
        "    Captioning과 VQA 태스크의 증강 전후 비교\n",
        "    \"\"\"\n",
        "    # 데이터 로드\n",
        "    df = pd.read_parquet(train_path)\n",
        "\n",
        "    # 태스크별로 샘플 선택\n",
        "    captioning_samples = df[df['task'].str.contains('caption', case=False)].sample(min(num_samples, len(df)))\n",
        "    vqa_samples = df[df['task'].str.contains('vqa|question', case=False)].sample(min(num_samples, len(df)))\n",
        "\n",
        "    # Augmentor 생성\n",
        "    augmentor = ImageAugmentor()\n",
        "\n",
        "    # Figure 설정\n",
        "    fig, axes = plt.subplots(num_samples * 2, 4, figsize=(16, num_samples * 8))\n",
        "    fig.suptitle('Image Augmentation Test: Captioning vs VQA', fontsize=16)\n",
        "\n",
        "    row = 0\n",
        "\n",
        "    # Captioning 샘플 처리\n",
        "    print(\"=\" * 60)\n",
        "    print(\"CAPTIONING SAMPLES (Strong Augmentation)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for idx, (_, sample) in enumerate(captioning_samples.iterrows()):\n",
        "        print(f\"\\nCaptioning Sample {idx+1}:\")\n",
        "        print(f\"Task: {sample['task']}\")\n",
        "        print(f\"Output: {sample['output'][:100]}...\")\n",
        "\n",
        "        # 원본 이미지 로드\n",
        "        try:\n",
        "            original_img = load_image_strict(sample['input'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 증강 3번 적용\n",
        "        augmented_imgs = []\n",
        "        for _ in range(3):\n",
        "            aug_img = augmentor.augment(original_img.copy(), sample['task'])\n",
        "            augmented_imgs.append(aug_img)\n",
        "\n",
        "        # 시각화\n",
        "        axes[row, 0].imshow(original_img)\n",
        "        axes[row, 0].set_title(f'Original (Caption {idx+1})', fontsize=10)\n",
        "        axes[row, 0].axis('off')\n",
        "\n",
        "        for j, aug_img in enumerate(augmented_imgs):\n",
        "            axes[row, j+1].imshow(aug_img)\n",
        "            axes[row, j+1].set_title(f'Augmented {j+1}', fontsize=10)\n",
        "            axes[row, j+1].axis('off')\n",
        "\n",
        "        row += 1\n",
        "\n",
        "    # VQA 샘플 처리\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"VQA SAMPLES (Minimal Augmentation)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for idx, (_, sample) in enumerate(vqa_samples.iterrows()):\n",
        "        print(f\"\\nVQA Sample {idx+1}:\")\n",
        "        print(f\"Task: {sample['task']}\")\n",
        "        print(f\"Question: {sample.get('question', 'N/A')}\")\n",
        "        print(f\"Answer: {sample['output'][:100]}...\")\n",
        "\n",
        "        # 원본 이미지 로드\n",
        "        try:\n",
        "            original_img = load_image_strict(sample['input'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 증강 3번 적용\n",
        "        augmented_imgs = []\n",
        "        for _ in range(3):\n",
        "            aug_img = augmentor.augment(original_img.copy(), sample['task'])\n",
        "            augmented_imgs.append(aug_img)\n",
        "\n",
        "        # 시각화\n",
        "        axes[row, 0].imshow(original_img)\n",
        "        axes[row, 0].set_title(f'Original (VQA {idx+1})', fontsize=10)\n",
        "        axes[row, 0].axis('off')\n",
        "\n",
        "        for j, aug_img in enumerate(augmented_imgs):\n",
        "            axes[row, j+1].imshow(aug_img)\n",
        "            axes[row, j+1].set_title(f'Augmented {j+1}', fontsize=10)\n",
        "            axes[row, j+1].axis('off')\n",
        "\n",
        "        row += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "# 증강 차이 정량적 분석\n",
        "def analyze_augmentation_difference(train_path):\n",
        "    \"\"\"\n",
        "    증강 강도를 정량적으로 분석\n",
        "    \"\"\"\n",
        "    df = pd.read_parquet(train_path)\n",
        "    augmentor = ImageAugmentor()\n",
        "\n",
        "    results = {\n",
        "        'captioning': {'pixel_diff': [], 'color_diff': []},\n",
        "        'vqa': {'pixel_diff': [], 'color_diff': []}\n",
        "    }\n",
        "\n",
        "    # 각 태스크별로 10개 샘플 분석\n",
        "    for task_type in ['caption', 'vqa']:\n",
        "        samples = df[df['task'].str.contains(task_type, case=False)].head(10)\n",
        "\n",
        "        for _, sample in samples.iterrows():\n",
        "            try:\n",
        "                # 원본 이미지\n",
        "                original = load_image_strict(sample['input'])\n",
        "                original_array = np.array(original)\n",
        "\n",
        "                # 증강 이미지\n",
        "                augmented = augmentor.augment(original.copy(), sample['task'])\n",
        "                augmented_array = np.array(augmented)\n",
        "\n",
        "                # 픽셀 차이 계산\n",
        "                pixel_diff = np.mean(np.abs(original_array - augmented_array))\n",
        "\n",
        "                # 색상 히스토그램 차이\n",
        "                orig_hist = np.histogram(original_array, bins=256)[0]\n",
        "                aug_hist = np.histogram(augmented_array, bins=256)[0]\n",
        "                color_diff = np.sum(np.abs(orig_hist - aug_hist))\n",
        "\n",
        "                task_key = 'captioning' if 'caption' in task_type else 'vqa'\n",
        "                results[task_key]['pixel_diff'].append(pixel_diff)\n",
        "                results[task_key]['color_diff'].append(color_diff)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sample: {e}\")\n",
        "                continue\n",
        "\n",
        "    # 결과 출력\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"AUGMENTATION STRENGTH ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for task in results:\n",
        "        if results[task]['pixel_diff']:\n",
        "            avg_pixel = np.mean(results[task]['pixel_diff'])\n",
        "            avg_color = np.mean(results[task]['color_diff'])\n",
        "\n",
        "            print(f\"\\n{task.upper()}:\")\n",
        "            print(f\"  Average Pixel Difference: {avg_pixel:.2f}\")\n",
        "            print(f\"  Average Color Histogram Difference: {avg_color:.2f}\")\n",
        "\n",
        "            # 증강 강도 판정\n",
        "            if avg_pixel < 5:\n",
        "                strength = \"Very Weak\"\n",
        "            elif avg_pixel < 15:\n",
        "                strength = \"Weak\"\n",
        "            elif avg_pixel < 30:\n",
        "                strength = \"Moderate\"\n",
        "            else:\n",
        "                strength = \"Strong\"\n",
        "\n",
        "            print(f\"  Augmentation Strength: {strength}\")\n",
        "\n",
        "    # 시각화\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    # Pixel difference 비교\n",
        "    axes[0].bar(['Captioning', 'VQA'],\n",
        "                [np.mean(results['captioning']['pixel_diff']),\n",
        "                 np.mean(results['vqa']['pixel_diff'])])\n",
        "    axes[0].set_title('Average Pixel Difference')\n",
        "    axes[0].set_ylabel('Pixel Difference')\n",
        "\n",
        "    # Color difference 비교\n",
        "    axes[1].bar(['Captioning', 'VQA'],\n",
        "                [np.mean(results['captioning']['color_diff']),\n",
        "                 np.mean(results['vqa']['color_diff'])])\n",
        "    axes[1].set_title('Average Color Histogram Difference')\n",
        "    axes[1].set_ylabel('Histogram Difference')\n",
        "\n",
        "    plt.suptitle('Augmentation Strength Comparison: Captioning vs VQA')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 단일 이미지 증강 테스트\n",
        "def test_single_augmentation(image_path, task=\"captioning\"):\n",
        "    \"\"\"\n",
        "    단일 이미지로 증강 테스트\n",
        "    \"\"\"\n",
        "    augmentor = ImageAugmentor()\n",
        "\n",
        "    # 이미지 로드\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # 6번 증강\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    fig.suptitle(f'Single Image Augmentation Test - Task: {task}', fontsize=14)\n",
        "\n",
        "    # 원본\n",
        "    axes[0, 0].imshow(img)\n",
        "    axes[0, 0].set_title('Original')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    # 증강 7번\n",
        "    positions = [(0, 1), (0, 2), (0, 3), (1, 0), (1, 1), (1, 2), (1, 3)]\n",
        "    for i, (row, col) in enumerate(positions):\n",
        "        aug_img = augmentor.augment(img.copy(), task)\n",
        "        axes[row, col].imshow(aug_img)\n",
        "        axes[row, col].set_title(f'Augmented {i+1}')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# 실행 예시\n",
        "if __name__ == \"__main__\":\n",
        "    train_path = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/image_train.parquet\"\n",
        "\n",
        "    # 1. 증강 시각화 테스트\n",
        "    print(\"Testing augmentation on samples...\")\n",
        "    fig = test_augmentation(train_path, num_samples=3)\n",
        "\n",
        "    # 2. 증강 강도 분석\n",
        "    print(\"\\nAnalyzing augmentation strength...\")\n",
        "    analyze_augmentation_difference(train_path)\n",
        "\n",
        "    # 3. 저장 (선택사항)\n",
        "    fig.savefig('/content/drive/MyDrive/Colab Notebooks/wook/augmentation_test.png', dpi=150, bbox_inches='tight')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6neVeczmonlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Step 1: 체크포인트 백업\n",
        "checkpoint_4000 = \"/content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-4000\"\n",
        "backup_path = checkpoint_4000 + \"_backup\"\n",
        "\n",
        "if not os.path.exists(backup_path):\n",
        "    shutil.copytree(checkpoint_4000, backup_path)\n",
        "    print(f\"Backup created: {backup_path}\")\n",
        "\n",
        "# Step 2: optimizer.pt 제거 (충돌 방지)\n",
        "optimizer_path = os.path.join(checkpoint_4000, \"optimizer.pt\")\n",
        "if os.path.exists(optimizer_path):\n",
        "    os.remove(optimizer_path)\n",
        "    print(\"Removed optimizer.pt\")\n",
        "\n",
        "# Step 3: trainer_state.json 수정\n",
        "import json\n",
        "state_path = os.path.join(checkpoint_4000, \"trainer_state.json\")\n",
        "if os.path.exists(state_path):\n",
        "    with open(state_path, 'r') as f:\n",
        "        state = json.load(f)\n",
        "\n",
        "    # 설정 업데이트\n",
        "    state['eval_steps'] = 500\n",
        "    state['save_steps'] = 500\n",
        "    state['learning_rate'] = 3e-5\n",
        "\n",
        "    with open(state_path, 'w') as f:\n",
        "        json.dump(state, f, indent=2)\n",
        "    print(\"Updated trainer_state.json\")"
      ],
      "metadata": {
        "id": "SzR16Q8s8Rt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495021a1-ac7a-45f8-d931-a9ea27c8b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backup created: /content/drive/MyDrive/Colab Notebooks/wook/fine-tuning/datasets/qlora/qlora-out/checkpoint-4000_backup\n",
            "Updated trainer_state.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O projector_finetune.py https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/projector_finetune.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR_eXlLguNBV",
        "outputId": "cb927ae3-805d-48c5-f3e3-5be090a4e764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-25 10:31:14--  https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/projector_finetune.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27026 (26K) [text/plain]\n",
            "Saving to: ‘projector_finetune.py’\n",
            "\n",
            "\rprojector_finetune.   0%[                    ]       0  --.-KB/s               \rprojector_finetune. 100%[===================>]  26.39K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-08-25 10:31:14 (10.4 MB/s) - ‘projector_finetune.py’ saved [27026/27026]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWsFzItB5pFr",
        "outputId": "aba92e23-b20a-48b1-8cfc-a8793b0353bf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.46 in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Collecting transformers>=4.46\n",
            "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.34 in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Requirement already satisfied: peft>=0.11 in /usr/local/lib/python3.12/dist-packages (0.17.0)\n",
            "Collecting peft>=0.11\n",
            "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting requests\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.46) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34) (2.8.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.46) (1.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=0.34) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.34) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34) (3.0.2)\n",
            "Downloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests, scikit-learn, pandas, transformers, bitsandbytes, peft\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.2\n",
            "    Uninstalling transformers-4.55.2:\n",
            "      Successfully uninstalled transformers-4.55.2\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.0\n",
            "    Uninstalling peft-0.17.0:\n",
            "      Successfully uninstalled peft-0.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.47.0 pandas-2.3.2 peft-0.17.1 requests-2.32.5 scikit-learn-1.7.1 transformers-4.55.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"transformers>=4.46\" \"accelerate>=0.34\" \"peft>=0.11\" bitsandbytes pandas pillow requests scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O llm_projector_finetune.py https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/llm_projector_finetune.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-J3X8VaoG0y",
        "outputId": "affca7b8-9339-43f8-9d24-e1e84ad9862b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-25 10:55:01--  https://raw.githubusercontent.com/ksw0425/deeplearning_challenge/refs/heads/main/llm_projector_finetune.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26002 (25K) [text/plain]\n",
            "Saving to: ‘llm_projector_finetune.py’\n",
            "\n",
            "llm_projector_finet 100%[===================>]  25.39K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-08-25 10:55:01 (9.32 MB/s) - ‘llm_projector_finetune.py’ saved [26002/26002]\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}